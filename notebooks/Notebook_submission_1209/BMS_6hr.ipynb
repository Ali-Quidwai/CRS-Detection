{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmIOFpRcNAer"
   },
   "source": [
    "**1. Dependencies and Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOMF68iUJvCr",
    "outputId": "5bce6c34-46b3-46f1-fa83-a018736923f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting tslearn\n",
      "  Downloading tslearn-0.6.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from tslearn) (1.5.2)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from tslearn) (0.60.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from tslearn) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->tslearn) (0.43.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->tslearn) (3.5.0)\n",
      "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tslearn-0.6.3-py3-none-any.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tslearn, catboost\n",
      "Successfully installed catboost-1.2.7 tslearn-0.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost tslearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCmBC7Punn7G"
   },
   "source": [
    "**2. Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oS8T5tgsKFHJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.dates as mdates\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4DdauxBNDaf"
   },
   "source": [
    "**3. Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIDh8sn_KHqT",
    "outputId": "9f209af3-b85e-4ba1-ac98-b93dd83dac2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-9f82b15b9ae4>:1: DtypeWarning: Columns (38,51,53,54,84,108,122,139,142,159,160,161) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"final_data_clipped.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  patient_id    pr_display spo2_display resp_display  \\\n",
      "0           0        7001  71 beats/min          96%          17%   \n",
      "1           1        7001  71 beats/min          96%          17%   \n",
      "2           2        7001  71 beats/min          96%          17%   \n",
      "3           3        7001  71 beats/min          96%          17%   \n",
      "4           4        7001  71 beats/min          96%          17%   \n",
      "\n",
      "   pulse_rate_obscount  pulse_rate_avg  pulse_rate_min  pulse_rate_max  \\\n",
      "0                 10.0           70.01           66.63           71.52   \n",
      "1                 10.0           70.01           66.63           71.52   \n",
      "2                 10.0           70.01           66.63           71.52   \n",
      "3                 10.0           70.01           66.63           71.52   \n",
      "4                 10.0           70.01           66.63           71.52   \n",
      "\n",
      "   pulse_rate_iqr  ...  QC Deviation from median.1  \\\n",
      "0            2.88  ...                    0.047985   \n",
      "1            2.88  ...                    0.047985   \n",
      "2            2.88  ...                    0.048813   \n",
      "3            2.88  ...                    0.049641   \n",
      "4            2.88  ...                    0.050469   \n",
      "\n",
      "   Weight at time of infusion               precise_datetime  \\\n",
      "0                   74.325238  2022-10-21 08:00:00.000000000   \n",
      "1                   74.325238  2022-10-21 08:00:00.000000000   \n",
      "2                   74.325238  2022-10-21 08:14:32.727272704   \n",
      "3                   74.325238  2022-10-21 08:29:05.454545408   \n",
      "4                   74.325238  2022-10-21 08:43:38.181818112   \n",
      "\n",
      "            CRS intervention   CRS Grade (nurse)  Temperature  SpO2   BP   HR  \\\n",
      "0  Tocilizumab x 1 on 1/22/24                1.0        100.9   WNL  WNL  WNL   \n",
      "1  Tocilizumab x 1 on 1/22/24                NaN          NaN   NaN  NaN  NaN   \n",
      "2  Tocilizumab x 1 on 1/22/24                NaN          NaN   NaN  NaN  NaN   \n",
      "3  Tocilizumab x 1 on 1/22/24                NaN          NaN   NaN  NaN  NaN   \n",
      "4  Tocilizumab x 1 on 1/22/24                NaN          NaN   NaN  NaN  NaN   \n",
      "\n",
      "   Temperature_C  \n",
      "0      38.277778  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "\n",
      "[5 rows x 163 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../Datasets/final_data_clipped.csv\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrNWeCBxnsyB"
   },
   "source": [
    "**4. Exploratory Data Analysis and Cleaning**\n",
    "\n",
    "In this section, relevant features are identified and subsets are created based on the type of agents (JNJ or BMS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2N4Wm754KUXy"
   },
   "outputs": [],
   "source": [
    "complete_set = ['PT_ID','CRS on date (0 No, 1 Yes)','Agent (JNJ/BMS/Caribou)','datetime', 'spo2_avg', 'pulse_rate_avg','respiratory_rate_avg', 'covered_skin_temperature_avg','covered_axil_temperature_avg','Highest Ferritin',\n",
    " 'Highest CRP','IL8',\n",
    " 'TNFRSF9',\n",
    " 'TIE2',\n",
    " 'MCP-3',\n",
    " 'CD40-L',\n",
    " 'IL-1 alpha',\n",
    " 'CD244',\n",
    " 'EGF',\n",
    " 'ANGPT1',\n",
    " 'IL7',\n",
    " 'PGF',\n",
    " 'IL6',\n",
    " 'ADGRG1',\n",
    " 'MCP-1',\n",
    " 'CRTAM',\n",
    " 'CXCL11',\n",
    " 'MCP-4',\n",
    " 'TRAIL',\n",
    " 'FGF2',\n",
    " 'CXCL9',\n",
    " 'CD8A',\n",
    " 'CAIX',\n",
    " 'MUC-16',\n",
    " 'ADA',\n",
    " 'CD4',\n",
    " 'NOS3',\n",
    " 'IL2',\n",
    " 'Gal-9',\n",
    " 'VEGFR-2',\n",
    " 'CD40',\n",
    " 'IL18',\n",
    " 'GZMH',\n",
    " 'KIR3DL1',\n",
    " 'LAP TGF-beta-1',\n",
    " 'CXCL1',\n",
    " 'TNFSF14',\n",
    " 'IL33',\n",
    " 'TWEAK',\n",
    " 'PDGF subunit B',\n",
    " 'PDCD1',\n",
    " 'FASLG',\n",
    " 'CD28',\n",
    " 'CCL19',\n",
    " 'MCP-2',\n",
    " 'CCL4',\n",
    " 'IL15',\n",
    " 'Gal-1',\n",
    " 'PD-L1',\n",
    " 'CD27',\n",
    " 'CXCL5',\n",
    " 'IL5',\n",
    " 'HGF',\n",
    " 'GZMA',\n",
    " 'HO-1',\n",
    " 'CX3CL1',\n",
    " 'CXCL10',\n",
    " 'CD70',\n",
    " 'IL10',\n",
    " 'TNFRSF12A',\n",
    " 'CCL23',\n",
    " 'CD5',\n",
    " 'CCL3',\n",
    " 'MMP7',\n",
    " 'ARG1',\n",
    " 'NCR1',\n",
    " 'DCN',\n",
    " 'TNFRSF21',\n",
    " 'TNFRSF4',\n",
    " 'MIC-A/B',\n",
    " 'CCL17',\n",
    " 'ANGPT2',\n",
    " 'PTN',\n",
    " 'CXCL12',\n",
    " 'IFN-gamma',\n",
    " 'LAMP3',\n",
    " 'CASP-8',\n",
    " 'ICOSLG',\n",
    " 'MMP12',\n",
    " 'CXCL13',\n",
    " 'PD-L2',\n",
    " 'VEGFA',\n",
    " 'IL4',\n",
    " 'LAG3',\n",
    " 'IL12RB1',\n",
    " 'IL13',\n",
    " 'CCL20',\n",
    " 'TNF',\n",
    " 'KLRD1',\n",
    " 'GZMB',\n",
    " 'CD83',\n",
    " 'IL12',\n",
    " 'CSF-1',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLiv5lgTNn0F"
   },
   "source": [
    "Taking different feature sets for JNJ and BMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "EkKmnEkUKZPe",
    "outputId": "feb2bc10-df32-4264-e6c4-47f22704487f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df_subset_BMS"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-30ab7b25-1ff9-4be2-9205-003fd5388fca\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FASLG</th>\n",
       "      <th>MCP-1</th>\n",
       "      <th>CD8A</th>\n",
       "      <th>CD70</th>\n",
       "      <th>CCL19</th>\n",
       "      <th>Highest CRP</th>\n",
       "      <th>KLRD1</th>\n",
       "      <th>TNFRSF9</th>\n",
       "      <th>CXCL12</th>\n",
       "      <th>ADGRG1</th>\n",
       "      <th>...</th>\n",
       "      <th>pulse_rate_avg</th>\n",
       "      <th>respiratory_rate_avg</th>\n",
       "      <th>covered_skin_temperature_avg</th>\n",
       "      <th>IL8</th>\n",
       "      <th>IL6</th>\n",
       "      <th>CXCL10</th>\n",
       "      <th>IFN-gamma</th>\n",
       "      <th>CCL23</th>\n",
       "      <th>CASP-8</th>\n",
       "      <th>CXCL13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.806320</td>\n",
       "      <td>11.550530</td>\n",
       "      <td>8.241330</td>\n",
       "      <td>3.730040</td>\n",
       "      <td>10.739640</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>4.535950</td>\n",
       "      <td>5.676640</td>\n",
       "      <td>2.734640</td>\n",
       "      <td>2.15725</td>\n",
       "      <td>...</td>\n",
       "      <td>70.01</td>\n",
       "      <td>24.35</td>\n",
       "      <td>27.650</td>\n",
       "      <td>5.570850</td>\n",
       "      <td>4.754540</td>\n",
       "      <td>9.135090</td>\n",
       "      <td>5.938620</td>\n",
       "      <td>10.893300</td>\n",
       "      <td>4.387440</td>\n",
       "      <td>6.721580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.806320</td>\n",
       "      <td>11.550530</td>\n",
       "      <td>8.241330</td>\n",
       "      <td>3.730040</td>\n",
       "      <td>10.739640</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>4.535950</td>\n",
       "      <td>5.676640</td>\n",
       "      <td>2.734640</td>\n",
       "      <td>2.15725</td>\n",
       "      <td>...</td>\n",
       "      <td>70.01</td>\n",
       "      <td>24.35</td>\n",
       "      <td>27.650</td>\n",
       "      <td>5.570850</td>\n",
       "      <td>4.754540</td>\n",
       "      <td>9.135090</td>\n",
       "      <td>5.938620</td>\n",
       "      <td>10.893300</td>\n",
       "      <td>4.387440</td>\n",
       "      <td>6.721580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.810654</td>\n",
       "      <td>11.572441</td>\n",
       "      <td>8.239465</td>\n",
       "      <td>3.734411</td>\n",
       "      <td>10.745863</td>\n",
       "      <td>22.574747</td>\n",
       "      <td>4.536448</td>\n",
       "      <td>5.677832</td>\n",
       "      <td>2.735678</td>\n",
       "      <td>2.15513</td>\n",
       "      <td>...</td>\n",
       "      <td>70.01</td>\n",
       "      <td>19.86</td>\n",
       "      <td>27.735</td>\n",
       "      <td>5.575702</td>\n",
       "      <td>4.773422</td>\n",
       "      <td>9.158341</td>\n",
       "      <td>6.003697</td>\n",
       "      <td>10.897528</td>\n",
       "      <td>4.403390</td>\n",
       "      <td>6.724164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.814989</td>\n",
       "      <td>11.594352</td>\n",
       "      <td>8.237599</td>\n",
       "      <td>3.738781</td>\n",
       "      <td>10.752086</td>\n",
       "      <td>22.549495</td>\n",
       "      <td>4.536946</td>\n",
       "      <td>5.679023</td>\n",
       "      <td>2.736717</td>\n",
       "      <td>2.15301</td>\n",
       "      <td>...</td>\n",
       "      <td>70.01</td>\n",
       "      <td>15.37</td>\n",
       "      <td>27.820</td>\n",
       "      <td>5.580553</td>\n",
       "      <td>4.792303</td>\n",
       "      <td>9.181591</td>\n",
       "      <td>6.068774</td>\n",
       "      <td>10.901756</td>\n",
       "      <td>4.419340</td>\n",
       "      <td>6.726747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.819323</td>\n",
       "      <td>11.616262</td>\n",
       "      <td>8.235734</td>\n",
       "      <td>3.743152</td>\n",
       "      <td>10.758310</td>\n",
       "      <td>22.524242</td>\n",
       "      <td>4.537444</td>\n",
       "      <td>5.680215</td>\n",
       "      <td>2.737755</td>\n",
       "      <td>2.15089</td>\n",
       "      <td>...</td>\n",
       "      <td>70.01</td>\n",
       "      <td>11.77</td>\n",
       "      <td>27.780</td>\n",
       "      <td>5.585405</td>\n",
       "      <td>4.811185</td>\n",
       "      <td>9.204842</td>\n",
       "      <td>6.133852</td>\n",
       "      <td>10.905983</td>\n",
       "      <td>4.435289</td>\n",
       "      <td>6.729331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30ab7b25-1ff9-4be2-9205-003fd5388fca')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-30ab7b25-1ff9-4be2-9205-003fd5388fca button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-30ab7b25-1ff9-4be2-9205-003fd5388fca');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-074239e3-673b-4743-80a6-753608ad0e2c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-074239e3-673b-4743-80a6-753608ad0e2c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-074239e3-673b-4743-80a6-753608ad0e2c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      FASLG      MCP-1      CD8A      CD70      CCL19  Highest CRP     KLRD1  \\\n",
       "0  5.806320  11.550530  8.241330  3.730040  10.739640    22.600000  4.535950   \n",
       "1  5.806320  11.550530  8.241330  3.730040  10.739640    22.600000  4.535950   \n",
       "2  5.810654  11.572441  8.239465  3.734411  10.745863    22.574747  4.536448   \n",
       "3  5.814989  11.594352  8.237599  3.738781  10.752086    22.549495  4.536946   \n",
       "4  5.819323  11.616262  8.235734  3.743152  10.758310    22.524242  4.537444   \n",
       "\n",
       "    TNFRSF9    CXCL12   ADGRG1  ... pulse_rate_avg  respiratory_rate_avg  \\\n",
       "0  5.676640  2.734640  2.15725  ...          70.01                 24.35   \n",
       "1  5.676640  2.734640  2.15725  ...          70.01                 24.35   \n",
       "2  5.677832  2.735678  2.15513  ...          70.01                 19.86   \n",
       "3  5.679023  2.736717  2.15301  ...          70.01                 15.37   \n",
       "4  5.680215  2.737755  2.15089  ...          70.01                 11.77   \n",
       "\n",
       "   covered_skin_temperature_avg       IL8       IL6    CXCL10  IFN-gamma  \\\n",
       "0                        27.650  5.570850  4.754540  9.135090   5.938620   \n",
       "1                        27.650  5.570850  4.754540  9.135090   5.938620   \n",
       "2                        27.735  5.575702  4.773422  9.158341   6.003697   \n",
       "3                        27.820  5.580553  4.792303  9.181591   6.068774   \n",
       "4                        27.780  5.585405  4.811185  9.204842   6.133852   \n",
       "\n",
       "       CCL23    CASP-8    CXCL13  \n",
       "0  10.893300  4.387440  6.721580  \n",
       "1  10.893300  4.387440  6.721580  \n",
       "2  10.897528  4.403390  6.724164  \n",
       "3  10.901756  4.419340  6.726747  \n",
       "4  10.905983  4.435289  6.729331  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_test_JNJ = ['Agent (JNJ/BMS/Caribou)', 'CAIX', 'CASP-8', 'CCL23', 'CD40-L', 'CD70',\n",
    "'CRS on date (0 No, 1 Yes)', 'CXCL10', 'CXCL11', 'CXCL13', 'FASLG',\n",
    "'FGF2', 'GZMB', 'GZMH', 'Highest CRP', 'Highest Ferritin', 'IFN-gamma',\n",
    "'IL10', 'IL13', 'IL15', 'IL6', 'IL8', 'MCP-2', 'MMP12', 'PT_ID',\n",
    "'TIE2', 'TNFRSF9', 'TNFSF14', 'covered_skin_temperature_avg', 'datetime',\n",
    "'pulse_rate_avg', 'respiratory_rate_avg', 'spo2_avg']\n",
    "columns_test_BMS = ['FASLG', 'MCP-1', 'CD8A', 'CD70', 'CCL19', 'Highest CRP', 'KLRD1', 'TNFRSF9', 'CXCL12', 'ADGRG1', 'IL2', 'CXCL11', 'GZMH', 'TRAIL', 'IL5', 'TNFSF14', 'HO-1', 'CXCL1', 'CXCL5', 'CD244',\n",
    " 'PT_ID', 'CRS on date (0 No, 1 Yes)', 'Agent (JNJ/BMS/Caribou)', 'datetime', 'spo2_avg', 'pulse_rate_avg', 'respiratory_rate_avg', 'covered_skin_temperature_avg', 'IL8', 'IL6', 'CXCL10',\n",
    " 'IFN-gamma', 'CCL23', 'CASP-8', 'CXCL13']\n",
    "df_subset_JNJ = df[columns_test_JNJ]\n",
    "df_subset_BMS = df[columns_test_BMS]\n",
    "df_subset_JNJ.head(5)\n",
    "df_subset_BMS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tuh3D-gPKbdC"
   },
   "outputs": [],
   "source": [
    "df_JNJ = df_subset_JNJ[(df_subset_JNJ['Agent (JNJ/BMS/Caribou)']=='JNJ') | (df_subset_JNJ['Agent (JNJ/BMS/Caribou)']=='JNJ OOS')]\n",
    "df_BMS = df_subset_BMS[(df_subset_BMS['Agent (JNJ/BMS/Caribou)']=='BMS')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfZgZlzJOyW9"
   },
   "source": [
    "**5. Data Individualization and Baseline Adjustment**\n",
    "\n",
    "Columns for JNJ are chosen here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "7wr9F1CpKd5Q",
    "outputId": "2ad81ecd-a3bf-4958-8b25-7b964c41d086"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ac375001-1d66-4398-a368-2c37e491ad9f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FASLG</th>\n",
       "      <th>MCP-1</th>\n",
       "      <th>CD8A</th>\n",
       "      <th>CD70</th>\n",
       "      <th>CCL19</th>\n",
       "      <th>Highest CRP</th>\n",
       "      <th>KLRD1</th>\n",
       "      <th>TNFRSF9</th>\n",
       "      <th>CXCL12</th>\n",
       "      <th>ADGRG1</th>\n",
       "      <th>...</th>\n",
       "      <th>pulse_rate_avg</th>\n",
       "      <th>respiratory_rate_avg</th>\n",
       "      <th>covered_skin_temperature_avg</th>\n",
       "      <th>IL8</th>\n",
       "      <th>IL6</th>\n",
       "      <th>CXCL10</th>\n",
       "      <th>IFN-gamma</th>\n",
       "      <th>CCL23</th>\n",
       "      <th>CASP-8</th>\n",
       "      <th>CXCL13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.021911</td>\n",
       "      <td>-0.001865</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>-0.025253</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>-0.00212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.49</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>0.023251</td>\n",
       "      <td>0.065077</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.015950</td>\n",
       "      <td>0.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.043822</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>0.008741</td>\n",
       "      <td>0.012446</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>-0.00424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.98</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>0.046501</td>\n",
       "      <td>0.130154</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.005167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013003</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>-0.075758</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>-0.00636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.58</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>0.056645</td>\n",
       "      <td>0.069752</td>\n",
       "      <td>0.195232</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>0.047849</td>\n",
       "      <td>0.007751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac375001-1d66-4398-a368-2c37e491ad9f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ac375001-1d66-4398-a368-2c37e491ad9f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ac375001-1d66-4398-a368-2c37e491ad9f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-1dbc3ceb-588b-4b4a-ad95-414f6ec63541\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1dbc3ceb-588b-4b4a-ad95-414f6ec63541')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-1dbc3ceb-588b-4b4a-ad95-414f6ec63541 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      FASLG     MCP-1      CD8A      CD70     CCL19  Highest CRP     KLRD1  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "2  0.004334  0.021911 -0.001865  0.004371  0.006223    -0.025253  0.000498   \n",
       "3  0.008669  0.043822 -0.003731  0.008741  0.012446    -0.050505  0.000996   \n",
       "4  0.013003  0.065732 -0.005596  0.013112  0.018670    -0.075758  0.001494   \n",
       "\n",
       "    TNFRSF9    CXCL12   ADGRG1  ...  pulse_rate_avg  respiratory_rate_avg  \\\n",
       "0  0.000000  0.000000  0.00000  ...             0.0                  0.00   \n",
       "1  0.000000  0.000000  0.00000  ...             0.0                  0.00   \n",
       "2  0.001192  0.001038 -0.00212  ...             0.0                 -4.49   \n",
       "3  0.002383  0.002077 -0.00424  ...             0.0                 -8.98   \n",
       "4  0.003575  0.003115 -0.00636  ...             0.0                -12.58   \n",
       "\n",
       "   covered_skin_temperature_avg       IL8       IL6    CXCL10  IFN-gamma  \\\n",
       "0                         0.000  0.000000  0.000000  0.000000   0.000000   \n",
       "1                         0.000  0.000000  0.000000  0.000000   0.000000   \n",
       "2                         0.085  0.004852  0.018882  0.023251   0.065077   \n",
       "3                         0.170  0.009703  0.037763  0.046501   0.130154   \n",
       "4                         0.130  0.014555  0.056645  0.069752   0.195232   \n",
       "\n",
       "      CCL23    CASP-8    CXCL13  \n",
       "0  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  \n",
       "2  0.004228  0.015950  0.002584  \n",
       "3  0.008456  0.031900  0.005167  \n",
       "4  0.012683  0.047849  0.007751  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_BMS.copy()\n",
    "\n",
    "baseline = data.groupby('PT_ID').first().reset_index()\n",
    "\n",
    "# Subtract the baseline values for numeric columns\n",
    "columns_to_individualize = [col for col in columns_test_BMS if col not in ['PT_ID', 'CRS on date (0 No, 1 Yes)', 'Agent (JNJ/BMS/Caribou)','datetime']]\n",
    "\n",
    "for col in columns_to_individualize:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    data[col] = data[col] - data.groupby('PT_ID')[col].transform('first')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTdK-GWaO7c5"
   },
   "source": [
    "**6. Feature Engineering: Rolling and Lagged Features**\n",
    "\n",
    "Additional features are generated to capture short-term trends and variability in the measurements. Past values and rolling statistics over a 6-hour window are computed to provide temporal context for the prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlZB5h9rKl3X",
    "outputId": "ecaf3cb8-8fe6-4e9f-f6d0-35aa7a08e954"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
      "<ipython-input-8-18d0b555f300>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
      "<ipython-input-8-18d0b555f300>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Define the window size for rolling statistics (e.g., past 6 hours)\n",
    "window_size = 6\n",
    "lag_size = 6\n",
    "time_interval = 30\n",
    "\n",
    "# Sort data by patient ID and datetime\n",
    "data = data.sort_values(by=['PT_ID', 'datetime'])\n",
    "\n",
    "# Function to create lagged features and rolling statistics\n",
    "def add_past_features(data, columns,lag_size):\n",
    "    for col in columns:\n",
    "        # Add lagged values\n",
    "        for lag_base in range(1, lag_size + 1):\n",
    "            lag = lag_base * time_interval\n",
    "            data[f'{col}_lag_{lag}'] = data.groupby('PT_ID')[col].shift(lag)\n",
    "\n",
    "        rolling_size = lag_size * time_interval\n",
    "        # Add rolling statistics\n",
    "        data[f'{col}_rolling_mean_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        data[f'{col}_rolling_std_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
    "        data[f'{col}_rolling_min_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
    "        data[f'{col}_rolling_max_{rolling_size}'] = data.groupby('PT_ID')[col].rolling(rolling_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "# Add past features for selected columns\n",
    "columns_to_process = [col for col in columns_test_BMS if col not in ['PT_ID','CRS on date (0 No, 1 Yes)','Agent (JNJ/BMS/Caribou)','datetime']]\n",
    "data = add_past_features(data, columns_to_process, lag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ineyrdBn7oE"
   },
   "source": [
    "**7. Creating column: CRS in 6 Hours**\n",
    "\n",
    "In this section, a binary target variable CRS_in_6_hours is created. It indicates whether a patient will experience CRS within the next 6 hours from any given measurement time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TL0YEmIZKuJ7"
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def assign_crs_in_6_hours(data):\n",
    "    \"\"\"\n",
    "    Assign CRS_in_6_hours for each row based on whether `datetime + 6 hours` falls within a CRS occurrence time frame.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): Input DataFrame with 'PT_ID', 'datetime', and 'CRS on date (0 No, 1 Yes)' columns.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with a new column 'CRS_in_6_hours'.\n",
    "    \"\"\"\n",
    "    # Ensure 'datetime' is a datetime object\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "    data = data.sort_values(by=['PT_ID', 'datetime'])\n",
    "\n",
    "    # Initialize a new column\n",
    "    data['CRS_in_6_hours'] = 0\n",
    "\n",
    "    # Process each patient group separately\n",
    "    for pt_id, group in data.groupby('PT_ID'):\n",
    "        # Sort by datetime for the current patient\n",
    "        group = group.sort_values('datetime')\n",
    "\n",
    "        # Identify CRS occurrence start and end timeframes\n",
    "        crs_start = group.index[(group['CRS on date (0 No, 1 Yes)'].shift(1) == 0) &\n",
    "                                (group['CRS on date (0 No, 1 Yes)'] == 1)].tolist()\n",
    "        crs_end = group.index[(group['CRS on date (0 No, 1 Yes)'].shift(1) == 1) &\n",
    "                              (group['CRS on date (0 No, 1 Yes)'] == 0)].tolist()\n",
    "\n",
    "        # If a CRS event starts but does not end, assume it continues until the last datetime\n",
    "        if len(crs_start) > len(crs_end):\n",
    "            crs_end.append(group.index[-1])\n",
    "\n",
    "        # Assign CRS_in_6_hours for each row\n",
    "        for start_idx, end_idx in zip(crs_start, crs_end):\n",
    "            crs_start_time = group.loc[start_idx, 'datetime']\n",
    "            crs_end_time = group.loc[end_idx, 'datetime']\n",
    "\n",
    "            # Any datetime + 6 hours within the CRS occurrence timeframe is set to 1\n",
    "            within_crs_timeframe = (group['datetime'] + timedelta(hours=6) >= crs_start_time) & \\\n",
    "                                   (group['datetime'] + timedelta(hours=6) <= crs_end_time)\n",
    "            data.loc[group[within_crs_timeframe].index, 'CRS_in_6_hours'] = 1\n",
    "\n",
    "    return data\n",
    "\n",
    "data = assign_crs_in_6_hours(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFIY0V5LX2h2",
    "outputId": "641c5788-c48f-4c03-a3cd-1f2491ab6718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "FASLG_lag_30               270\n",
      "FASLG_lag_60               540\n",
      "FASLG_lag_90               810\n",
      "FASLG_lag_120             1080\n",
      "FASLG_lag_150             1350\n",
      "                          ... \n",
      "CXCL13_lag_90              810\n",
      "CXCL13_lag_120            1080\n",
      "CXCL13_lag_150            1350\n",
      "CXCL13_lag_180            1620\n",
      "CXCL13_rolling_std_180       9\n",
      "Length: 217, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Filter columns with missing values\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "if missing_values.empty:\n",
    "    print(\"No missing values in the dataset.\")\n",
    "else:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yU2cbPeqYGgc",
    "outputId": "fe85f6f9-f61b-4e39-a21f-49c2fe52fcdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values remaining in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Handle lagged features: Fill missing values with 0\n",
    "lagged_columns = [col for col in data.columns if 'lag' in col]\n",
    "data[lagged_columns] = data[lagged_columns].fillna(0)\n",
    "\n",
    "# Handle rolling statistics: Forward-fill within each patient group\n",
    "rolling_columns = [col for col in data.columns if 'rolling' in col]\n",
    "data[rolling_columns] = data.groupby('PT_ID')[rolling_columns].ffill()\n",
    "\n",
    "# Fill any remaining missing values in rolling statistics with 0\n",
    "data[rolling_columns] = data[rolling_columns].fillna(0)\n",
    "\n",
    "# Separate numeric and non-numeric columns in other_columns\n",
    "other_columns = [col for col in data.columns if col not in lagged_columns + rolling_columns + ['PT_ID', 'datetime']]\n",
    "numeric_columns = [col for col in other_columns if data[col].dtype in ['int64', 'float64']]\n",
    "non_numeric_columns = [col for col in other_columns if col not in numeric_columns]\n",
    "\n",
    "# Handle numeric columns: Mean imputation\n",
    "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())\n",
    "\n",
    "# Handle non-numeric columns: Fill missing values with mode\n",
    "for col in non_numeric_columns:\n",
    "    mode_value = data[col].mode().iloc[0]\n",
    "    data[col] = data[col].fillna(mode_value)\n",
    "\n",
    "# Check for remaining missing values\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "if missing_values.empty:\n",
    "    print(\"No missing values remaining in the dataset.\")\n",
    "else:\n",
    "    print(\"Columns with remaining missing values:\")\n",
    "    print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "uSXhLzDEMgTz",
    "outputId": "dcfaac3c-c118-48ac-c01c-0d2459b74fea"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-37d0d137-a846-4f88-94e2-253cdcc02b60\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FASLG</th>\n",
       "      <th>MCP-1</th>\n",
       "      <th>CD8A</th>\n",
       "      <th>CD70</th>\n",
       "      <th>CCL19</th>\n",
       "      <th>Highest CRP</th>\n",
       "      <th>KLRD1</th>\n",
       "      <th>TNFRSF9</th>\n",
       "      <th>CXCL12</th>\n",
       "      <th>ADGRG1</th>\n",
       "      <th>...</th>\n",
       "      <th>CXCL13_lag_60</th>\n",
       "      <th>CXCL13_lag_90</th>\n",
       "      <th>CXCL13_lag_120</th>\n",
       "      <th>CXCL13_lag_150</th>\n",
       "      <th>CXCL13_lag_180</th>\n",
       "      <th>CXCL13_rolling_mean_180</th>\n",
       "      <th>CXCL13_rolling_std_180</th>\n",
       "      <th>CXCL13_rolling_min_180</th>\n",
       "      <th>CXCL13_rolling_max_180</th>\n",
       "      <th>CRS_in_6_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.021911</td>\n",
       "      <td>-0.001865</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>-0.025253</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>-0.002120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.043822</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>0.008741</td>\n",
       "      <td>0.012446</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>-0.004240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013003</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>-0.075758</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>-0.006360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017337</td>\n",
       "      <td>0.087643</td>\n",
       "      <td>-0.007461</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.024893</td>\n",
       "      <td>-0.101010</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>-0.008480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320609</th>\n",
       "      <td>0.221439</td>\n",
       "      <td>-1.509934</td>\n",
       "      <td>0.740310</td>\n",
       "      <td>-0.222933</td>\n",
       "      <td>1.218298</td>\n",
       "      <td>42.411220</td>\n",
       "      <td>-0.109863</td>\n",
       "      <td>0.124117</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>-0.547634</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384181</td>\n",
       "      <td>1.360940</td>\n",
       "      <td>1.337700</td>\n",
       "      <td>1.314459</td>\n",
       "      <td>1.291218</td>\n",
       "      <td>1.361328</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>1.291993</td>\n",
       "      <td>1.430662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320610</th>\n",
       "      <td>0.221551</td>\n",
       "      <td>-1.511560</td>\n",
       "      <td>0.740584</td>\n",
       "      <td>-0.223324</td>\n",
       "      <td>1.217921</td>\n",
       "      <td>42.411463</td>\n",
       "      <td>-0.109800</td>\n",
       "      <td>0.124070</td>\n",
       "      <td>0.154933</td>\n",
       "      <td>-0.547844</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384956</td>\n",
       "      <td>1.361715</td>\n",
       "      <td>1.338474</td>\n",
       "      <td>1.315233</td>\n",
       "      <td>1.291993</td>\n",
       "      <td>1.362102</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>1.292767</td>\n",
       "      <td>1.431437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320611</th>\n",
       "      <td>0.221664</td>\n",
       "      <td>-1.513187</td>\n",
       "      <td>0.740858</td>\n",
       "      <td>-0.223715</td>\n",
       "      <td>1.217544</td>\n",
       "      <td>42.411707</td>\n",
       "      <td>-0.109737</td>\n",
       "      <td>0.124024</td>\n",
       "      <td>0.154666</td>\n",
       "      <td>-0.548054</td>\n",
       "      <td>...</td>\n",
       "      <td>1.385730</td>\n",
       "      <td>1.362490</td>\n",
       "      <td>1.339249</td>\n",
       "      <td>1.316008</td>\n",
       "      <td>1.292767</td>\n",
       "      <td>1.362877</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>1.293542</td>\n",
       "      <td>1.432212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320612</th>\n",
       "      <td>0.221777</td>\n",
       "      <td>-1.514813</td>\n",
       "      <td>0.741132</td>\n",
       "      <td>-0.224105</td>\n",
       "      <td>1.217167</td>\n",
       "      <td>42.411951</td>\n",
       "      <td>-0.109673</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.154399</td>\n",
       "      <td>-0.548263</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386505</td>\n",
       "      <td>1.363264</td>\n",
       "      <td>1.340024</td>\n",
       "      <td>1.316783</td>\n",
       "      <td>1.293542</td>\n",
       "      <td>1.363652</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>1.294317</td>\n",
       "      <td>1.432987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320613</th>\n",
       "      <td>0.221890</td>\n",
       "      <td>-1.516440</td>\n",
       "      <td>0.741406</td>\n",
       "      <td>-0.224496</td>\n",
       "      <td>1.216790</td>\n",
       "      <td>42.412195</td>\n",
       "      <td>-0.109610</td>\n",
       "      <td>0.123931</td>\n",
       "      <td>0.154132</td>\n",
       "      <td>-0.548473</td>\n",
       "      <td>...</td>\n",
       "      <td>1.387280</td>\n",
       "      <td>1.364039</td>\n",
       "      <td>1.340798</td>\n",
       "      <td>1.317558</td>\n",
       "      <td>1.294317</td>\n",
       "      <td>1.364426</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>1.295092</td>\n",
       "      <td>1.433761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18375 rows × 346 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37d0d137-a846-4f88-94e2-253cdcc02b60')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-37d0d137-a846-4f88-94e2-253cdcc02b60 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-37d0d137-a846-4f88-94e2-253cdcc02b60');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-7214a9b5-2d3c-49a9-9823-d06e95a5d05a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7214a9b5-2d3c-49a9-9823-d06e95a5d05a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-7214a9b5-2d3c-49a9-9823-d06e95a5d05a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "           FASLG     MCP-1      CD8A      CD70     CCL19  Highest CRP  \\\n",
       "1       0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "2       0.004334  0.021911 -0.001865  0.004371  0.006223    -0.025253   \n",
       "3       0.008669  0.043822 -0.003731  0.008741  0.012446    -0.050505   \n",
       "4       0.013003  0.065732 -0.005596  0.013112  0.018670    -0.075758   \n",
       "5       0.017337  0.087643 -0.007461  0.017482  0.024893    -0.101010   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "320609  0.221439 -1.509934  0.740310 -0.222933  1.218298    42.411220   \n",
       "320610  0.221551 -1.511560  0.740584 -0.223324  1.217921    42.411463   \n",
       "320611  0.221664 -1.513187  0.740858 -0.223715  1.217544    42.411707   \n",
       "320612  0.221777 -1.514813  0.741132 -0.224105  1.217167    42.411951   \n",
       "320613  0.221890 -1.516440  0.741406 -0.224496  1.216790    42.412195   \n",
       "\n",
       "           KLRD1   TNFRSF9    CXCL12    ADGRG1  ...  CXCL13_lag_60  \\\n",
       "1       0.000000  0.000000  0.000000  0.000000  ...       0.000000   \n",
       "2       0.000498  0.001192  0.001038 -0.002120  ...       0.000000   \n",
       "3       0.000996  0.002383  0.002077 -0.004240  ...       0.000000   \n",
       "4       0.001494  0.003575  0.003115 -0.006360  ...       0.000000   \n",
       "5       0.001992  0.004766  0.004153 -0.008480  ...       0.000000   \n",
       "...          ...       ...       ...       ...  ...            ...   \n",
       "320609 -0.109863  0.124117  0.155200 -0.547634  ...       1.384181   \n",
       "320610 -0.109800  0.124070  0.154933 -0.547844  ...       1.384956   \n",
       "320611 -0.109737  0.124024  0.154666 -0.548054  ...       1.385730   \n",
       "320612 -0.109673  0.123977  0.154399 -0.548263  ...       1.386505   \n",
       "320613 -0.109610  0.123931  0.154132 -0.548473  ...       1.387280   \n",
       "\n",
       "        CXCL13_lag_90  CXCL13_lag_120  CXCL13_lag_150  CXCL13_lag_180  \\\n",
       "1            0.000000        0.000000        0.000000        0.000000   \n",
       "2            0.000000        0.000000        0.000000        0.000000   \n",
       "3            0.000000        0.000000        0.000000        0.000000   \n",
       "4            0.000000        0.000000        0.000000        0.000000   \n",
       "5            0.000000        0.000000        0.000000        0.000000   \n",
       "...               ...             ...             ...             ...   \n",
       "320609       1.360940        1.337700        1.314459        1.291218   \n",
       "320610       1.361715        1.338474        1.315233        1.291993   \n",
       "320611       1.362490        1.339249        1.316008        1.292767   \n",
       "320612       1.363264        1.340024        1.316783        1.293542   \n",
       "320613       1.364039        1.340798        1.317558        1.294317   \n",
       "\n",
       "        CXCL13_rolling_mean_180  CXCL13_rolling_std_180  \\\n",
       "1                      0.000000                0.000000   \n",
       "2                      0.000861                0.001492   \n",
       "3                      0.001938                0.002474   \n",
       "4                      0.003100                0.003369   \n",
       "5                      0.004306                0.004219   \n",
       "...                         ...                     ...   \n",
       "320609                 1.361328                0.040366   \n",
       "320610                 1.362102                0.040366   \n",
       "320611                 1.362877                0.040366   \n",
       "320612                 1.363652                0.040366   \n",
       "320613                 1.364426                0.040366   \n",
       "\n",
       "        CXCL13_rolling_min_180  CXCL13_rolling_max_180  CRS_in_6_hours  \n",
       "1                     0.000000                0.000000               1  \n",
       "2                     0.000000                0.002584               1  \n",
       "3                     0.000000                0.005167               1  \n",
       "4                     0.000000                0.007751               1  \n",
       "5                     0.000000                0.010334               1  \n",
       "...                        ...                     ...             ...  \n",
       "320609                1.291993                1.430662               1  \n",
       "320610                1.292767                1.431437               1  \n",
       "320611                1.293542                1.432212               1  \n",
       "320612                1.294317                1.432987               1  \n",
       "320613                1.295092                1.433761               1  \n",
       "\n",
       "[18375 rows x 346 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['CRS_in_6_hours']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "6vNBqAo5MiRv",
    "outputId": "c9e40057-771a-4623-b979-b8cd2462e925"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-6d1a1579-8fe3-46f8-b9d9-db3d1c136ea7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FASLG</th>\n",
       "      <th>MCP-1</th>\n",
       "      <th>CD8A</th>\n",
       "      <th>CD70</th>\n",
       "      <th>CCL19</th>\n",
       "      <th>Highest CRP</th>\n",
       "      <th>KLRD1</th>\n",
       "      <th>TNFRSF9</th>\n",
       "      <th>CXCL12</th>\n",
       "      <th>ADGRG1</th>\n",
       "      <th>...</th>\n",
       "      <th>CXCL13_lag_60</th>\n",
       "      <th>CXCL13_lag_90</th>\n",
       "      <th>CXCL13_lag_120</th>\n",
       "      <th>CXCL13_lag_150</th>\n",
       "      <th>CXCL13_lag_180</th>\n",
       "      <th>CXCL13_rolling_mean_180</th>\n",
       "      <th>CXCL13_rolling_std_180</th>\n",
       "      <th>CXCL13_rolling_min_180</th>\n",
       "      <th>CXCL13_rolling_max_180</th>\n",
       "      <th>CRS_in_6_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.021911</td>\n",
       "      <td>-0.001865</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>-0.025253</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>-0.002120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.043822</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>0.008741</td>\n",
       "      <td>0.012446</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>-0.004240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013003</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>-0.075758</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>-0.006360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017337</td>\n",
       "      <td>0.087643</td>\n",
       "      <td>-0.007461</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.024893</td>\n",
       "      <td>-0.101010</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>-0.008480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.109554</td>\n",
       "      <td>-0.009326</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.031116</td>\n",
       "      <td>-0.126263</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>-0.010599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.026006</td>\n",
       "      <td>0.131465</td>\n",
       "      <td>-0.011192</td>\n",
       "      <td>0.026223</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>-0.151515</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>-0.012719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.030340</td>\n",
       "      <td>0.153376</td>\n",
       "      <td>-0.013057</td>\n",
       "      <td>0.030594</td>\n",
       "      <td>0.043563</td>\n",
       "      <td>-0.176768</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>-0.014839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.034675</td>\n",
       "      <td>0.175286</td>\n",
       "      <td>-0.014922</td>\n",
       "      <td>0.034964</td>\n",
       "      <td>0.049786</td>\n",
       "      <td>-0.202020</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>-0.016959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009301</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.039009</td>\n",
       "      <td>0.197197</td>\n",
       "      <td>-0.016787</td>\n",
       "      <td>0.039335</td>\n",
       "      <td>0.056009</td>\n",
       "      <td>-0.227273</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>-0.019079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010569</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 346 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d1a1579-8fe3-46f8-b9d9-db3d1c136ea7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6d1a1579-8fe3-46f8-b9d9-db3d1c136ea7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6d1a1579-8fe3-46f8-b9d9-db3d1c136ea7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-66f5353a-8e5d-4d75-b8ee-e2925e8eb63b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66f5353a-8e5d-4d75-b8ee-e2925e8eb63b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-66f5353a-8e5d-4d75-b8ee-e2925e8eb63b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       FASLG     MCP-1      CD8A      CD70     CCL19  Highest CRP     KLRD1  \\\n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "2   0.004334  0.021911 -0.001865  0.004371  0.006223    -0.025253  0.000498   \n",
       "3   0.008669  0.043822 -0.003731  0.008741  0.012446    -0.050505  0.000996   \n",
       "4   0.013003  0.065732 -0.005596  0.013112  0.018670    -0.075758  0.001494   \n",
       "5   0.017337  0.087643 -0.007461  0.017482  0.024893    -0.101010  0.001992   \n",
       "6   0.021672  0.109554 -0.009326  0.021853  0.031116    -0.126263  0.002490   \n",
       "7   0.026006  0.131465 -0.011192  0.026223  0.037339    -0.151515  0.002988   \n",
       "8   0.030340  0.153376 -0.013057  0.030594  0.043563    -0.176768  0.003486   \n",
       "9   0.034675  0.175286 -0.014922  0.034964  0.049786    -0.202020  0.003984   \n",
       "10  0.039009  0.197197 -0.016787  0.039335  0.056009    -0.227273  0.004482   \n",
       "\n",
       "     TNFRSF9    CXCL12    ADGRG1  ...  CXCL13_lag_60  CXCL13_lag_90  \\\n",
       "1   0.000000  0.000000  0.000000  ...            0.0            0.0   \n",
       "2   0.001192  0.001038 -0.002120  ...            0.0            0.0   \n",
       "3   0.002383  0.002077 -0.004240  ...            0.0            0.0   \n",
       "4   0.003575  0.003115 -0.006360  ...            0.0            0.0   \n",
       "5   0.004766  0.004153 -0.008480  ...            0.0            0.0   \n",
       "6   0.005958  0.005191 -0.010599  ...            0.0            0.0   \n",
       "7   0.007149  0.006230 -0.012719  ...            0.0            0.0   \n",
       "8   0.008341  0.007268 -0.014839  ...            0.0            0.0   \n",
       "9   0.009532  0.008306 -0.016959  ...            0.0            0.0   \n",
       "10  0.010724  0.009345 -0.019079  ...            0.0            0.0   \n",
       "\n",
       "    CXCL13_lag_120  CXCL13_lag_150  CXCL13_lag_180  CXCL13_rolling_mean_180  \\\n",
       "1              0.0             0.0             0.0                 0.000000   \n",
       "2              0.0             0.0             0.0                 0.000861   \n",
       "3              0.0             0.0             0.0                 0.001938   \n",
       "4              0.0             0.0             0.0                 0.003100   \n",
       "5              0.0             0.0             0.0                 0.004306   \n",
       "6              0.0             0.0             0.0                 0.005536   \n",
       "7              0.0             0.0             0.0                 0.006782   \n",
       "8              0.0             0.0             0.0                 0.008038   \n",
       "9              0.0             0.0             0.0                 0.009301   \n",
       "10             0.0             0.0             0.0                 0.010569   \n",
       "\n",
       "    CXCL13_rolling_std_180  CXCL13_rolling_min_180  CXCL13_rolling_max_180  \\\n",
       "1                 0.000000                     0.0                0.000000   \n",
       "2                 0.001492                     0.0                0.002584   \n",
       "3                 0.002474                     0.0                0.005167   \n",
       "4                 0.003369                     0.0                0.007751   \n",
       "5                 0.004219                     0.0                0.010334   \n",
       "6                 0.005043                     0.0                0.012918   \n",
       "7                 0.005849                     0.0                0.015501   \n",
       "8                 0.006643                     0.0                0.018085   \n",
       "9                 0.007428                     0.0                0.020668   \n",
       "10                0.008207                     0.0                0.023252   \n",
       "\n",
       "    CRS_in_6_hours  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "5                1  \n",
       "6                1  \n",
       "7                1  \n",
       "8                1  \n",
       "9                1  \n",
       "10               1  \n",
       "\n",
       "[10 rows x 346 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['CRS_in_6_hours']==1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he06UfXltrC6"
   },
   "source": [
    "**8. Model Training and Evaluation**\n",
    "\n",
    "In this section, the dataset is split by patients into training and test sets using K-fold cross-validation. Several models (LightGBM, CatBoost, XGBoost) are trained to predict CRS_in_6_hours. Random oversampling is used to handle class imbalance. The performance is evaluated using accuracy, AUC-ROC, and classification reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i-2UqpDyKsf"
   },
   "source": [
    "**a. LightGBM Model with Oversampling**\n",
    "\n",
    "\n",
    "A LightGBM classifier is trained and evaluated with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGV1nFouMqar",
    "outputId": "206a638d-e705-40f3-c9f1-21b7ab68a39b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Class distribution after oversampling:\n",
      "CRS_in_6_hours\n",
      "0    69255\n",
      "1    69255\n",
      "Name: count, dtype: int64\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 69255, number of negative: 69255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 83982\n",
      "[LightGBM] [Info] Number of data points in the train set: 138510, number of used features: 341\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.6517888770811193\n",
      "AUC-ROC Score: 0.4049197264645052\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78     24576\n",
      "           1       0.14      0.34      0.20      3654\n",
      "\n",
      "    accuracy                           0.65     28230\n",
      "   macro avg       0.51      0.52      0.49     28230\n",
      "weighted avg       0.78      0.65      0.70     28230\n",
      "\n",
      "\n",
      "Fold 2/5\n",
      "Class distribution after oversampling:\n",
      "CRS_in_6_hours\n",
      "0    78644\n",
      "1    78644\n",
      "Name: count, dtype: int64\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 78644, number of negative: 78644\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 83966\n",
      "[LightGBM] [Info] Number of data points in the train set: 157288, number of used features: 341\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.711698254131267\n",
      "AUC-ROC Score: 0.6423524023337186\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.99      0.83     15187\n",
      "           1       0.62      0.02      0.05      6235\n",
      "\n",
      "    accuracy                           0.71     21422\n",
      "   macro avg       0.67      0.51      0.44     21422\n",
      "weighted avg       0.69      0.71      0.60     21422\n",
      "\n",
      "\n",
      "Fold 3/5\n",
      "Class distribution after oversampling:\n",
      "CRS_in_6_hours\n",
      "0    67375\n",
      "1    67375\n",
      "Name: count, dtype: int64\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 67375, number of negative: 67375\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 83879\n",
      "[LightGBM] [Info] Number of data points in the train set: 134750, number of used features: 341\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.8377940727161626\n",
      "AUC-ROC Score: 0.720521365479992\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91     26456\n",
      "           1       0.67      0.30      0.42      6274\n",
      "\n",
      "    accuracy                           0.84     32730\n",
      "   macro avg       0.76      0.63      0.66     32730\n",
      "weighted avg       0.82      0.84      0.81     32730\n",
      "\n",
      "\n",
      "Fold 4/5\n",
      "Class distribution after oversampling:\n",
      "CRS_in_6_hours\n",
      "0    78075\n",
      "1    78075\n",
      "Name: count, dtype: int64\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 78075, number of negative: 78075\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 84159\n",
      "[LightGBM] [Info] Number of data points in the train set: 156150, number of used features: 341\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.8982460085450866\n",
      "AUC-ROC Score: 0.9261321896120562\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94     15756\n",
      "           1       0.54      0.69      0.61      2032\n",
      "\n",
      "    accuracy                           0.90     17788\n",
      "   macro avg       0.75      0.81      0.77     17788\n",
      "weighted avg       0.91      0.90      0.90     17788\n",
      "\n",
      "\n",
      "Fold 5/5\n",
      "Class distribution after oversampling:\n",
      "CRS_in_6_hours\n",
      "0    81975\n",
      "1    81975\n",
      "Name: count, dtype: int64\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 81975, number of negative: 81975\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.243815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84310\n",
      "[LightGBM] [Info] Number of data points in the train set: 163950, number of used features: 341\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9260551678298438\n",
      "AUC-ROC Score: 0.8985532407407407\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     11856\n",
      "           1       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           0.93     12036\n",
      "   macro avg       0.49      0.47      0.48     12036\n",
      "weighted avg       0.97      0.93      0.95     12036\n",
      "\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.8051164760606959\n",
      "Average AUC-ROC: 0.7184957849262026\n",
      "Aggregated Confusion Matrix:\n",
      " [[83517 10314]\n",
      " [13701  4674]]\n",
      "Accuracy for class 0: 0.8900789717683921\n",
      "Accuracy for class 1: 0.2543673469387755\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "if 'datetime' in data.columns:\n",
    "    data = data.drop(columns=['datetime'])\n",
    "if 'cutoff_date' in data.columns:\n",
    "    data = data.drop(columns=['cutoff_date'])\n",
    "\n",
    "drop_cols = ['PT_ID', 'CRS_in_6_hours', 'CRS on date (0 No, 1 Yes)', 'Agent (JNJ/BMS/Caribou)']\n",
    "feature_cols = [col for col in data.columns if col not in drop_cols]\n",
    "\n",
    "unique_patients = data['PT_ID'].unique()\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "cv_accuracies = []\n",
    "cv_auc_scores = []\n",
    "aggregate_conf_matrix = np.array([[0, 0],\n",
    "                                  [0, 0]])\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(unique_patients)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "\n",
    "    train_patients = unique_patients[train_idx]\n",
    "    test_patients = unique_patients[test_idx]\n",
    "\n",
    "    train_data = data[data['PT_ID'].isin(train_patients)]\n",
    "    test_data = data[data['PT_ID'].isin(test_patients)]\n",
    "\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data['CRS_in_6_hours']\n",
    "\n",
    "    X_test = test_data[feature_cols]\n",
    "    y_test = test_data['CRS_in_6_hours']\n",
    "\n",
    "    # Handle class imbalance with Random Oversampling\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Print class distribution after oversampling\n",
    "    print(\"Class distribution after oversampling:\")\n",
    "    print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "    lgbm_model = LGBMClassifier(\n",
    "        objective='binary',\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    lgbm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "    y_prob = lgbm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"AUC-ROC Score:\", auc_score)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    cv_accuracies.append(accuracy)\n",
    "    cv_auc_scores.append(auc_score)\n",
    "    aggregate_conf_matrix += conf_matrix\n",
    "\n",
    "# Aggregate results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(cv_accuracies)}\")\n",
    "print(f\"Average AUC-ROC: {np.mean(cv_auc_scores)}\")\n",
    "print(\"Aggregated Confusion Matrix:\\n\", aggregate_conf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = aggregate_conf_matrix.ravel()\n",
    "class0_accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "class1_accuracy = tp / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for class 0: {class0_accuracy}\")\n",
    "print(f\"Accuracy for class 1: {class1_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B71AFcFhyIKW"
   },
   "source": [
    "**b. CatBoost Model**\n",
    "\n",
    "\n",
    "CatBoost classifier is also tested. Class weights are used to handle class imbalance, and a similar cross-validation approach is followed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dANDt0crNEsA",
    "outputId": "7f324968-8731-4218-d322-f95d947680c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Best Threshold: 0.130\n",
      "Accuracy: 0.8066\n",
      "AUC-ROC: 0.6832\n",
      "Balanced Accuracy: 0.6113\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89     24576\n",
      "           1       0.29      0.35      0.32      3654\n",
      "\n",
      "    accuracy                           0.81     28230\n",
      "   macro avg       0.60      0.61      0.60     28230\n",
      "weighted avg       0.82      0.81      0.81     28230\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold 2/5\n",
      "Best Threshold: 0.010\n",
      "Accuracy: 0.7336\n",
      "AUC-ROC: 0.8914\n",
      "Balanced Accuracy: 0.5759\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.84     15187\n",
      "           1       0.64      0.20      0.30      6235\n",
      "\n",
      "    accuracy                           0.73     21422\n",
      "   macro avg       0.69      0.58      0.57     21422\n",
      "weighted avg       0.71      0.73      0.68     21422\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold 3/5\n",
      "Best Threshold: 0.030\n",
      "Accuracy: 0.7037\n",
      "AUC-ROC: 0.7017\n",
      "Balanced Accuracy: 0.6825\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80     26456\n",
      "           1       0.35      0.65      0.46      6274\n",
      "\n",
      "    accuracy                           0.70     32730\n",
      "   macro avg       0.62      0.68      0.63     32730\n",
      "weighted avg       0.79      0.70      0.73     32730\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold 4/5\n",
      "Best Threshold: 0.020\n",
      "Accuracy: 0.7633\n",
      "AUC-ROC: 0.8601\n",
      "Balanced Accuracy: 0.8449\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85     15756\n",
      "           1       0.32      0.95      0.48      2032\n",
      "\n",
      "    accuracy                           0.76     17788\n",
      "   macro avg       0.66      0.84      0.66     17788\n",
      "weighted avg       0.91      0.76      0.80     17788\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold 5/5\n",
      "Best Threshold: 0.450\n",
      "Accuracy: 0.9430\n",
      "AUC-ROC: 0.9710\n",
      "Balanced Accuracy: 0.9711\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     11856\n",
      "           1       0.21      1.00      0.34       180\n",
      "\n",
      "    accuracy                           0.94     12036\n",
      "   macro avg       0.60      0.97      0.66     12036\n",
      "weighted avg       0.99      0.94      0.96     12036\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.7900307692469462\n",
      "Average AUC-ROC: 0.8214880427007879\n",
      "Aggregated Confusion Matrix:\n",
      " [[77756 16075]\n",
      " [ 9687  8688]]\n",
      "Accuracy for class 0: 0.8286813526446484\n",
      "Accuracy for class 1: 0.47281632653061223\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Drop unnecessary columns if they exist\n",
    "if 'cutoff_date' in data.columns:\n",
    "    data = data.drop(columns=['cutoff_date'])\n",
    "\n",
    "if 'datetime' in data.columns:\n",
    "    data = data.drop(columns=['datetime'])\n",
    "\n",
    "# Define columns to drop and feature columns\n",
    "drop_cols = ['PT_ID', 'CRS on date (0 No, 1 Yes)', 'Agent (JNJ/BMS/Caribou)', 'CRS_in_6_hours']\n",
    "feature_cols = [col for col in data.columns if col not in drop_cols]\n",
    "\n",
    "# Unique patients and KFold\n",
    "unique_patients = data['PT_ID'].unique()\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Metrics storage\n",
    "cv_accuracies = []\n",
    "cv_auc_scores = []\n",
    "cv_classification_reports = []\n",
    "aggregate_conf_matrix = np.array([[0, 0],\n",
    "                                  [0, 0]])\n",
    "\n",
    "# Initialize CatBoost model\n",
    "catboost_model = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    iterations=100,\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    "    class_weights=[1, 2.0]  # Adjust based on class imbalance\n",
    ")\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(unique_patients)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "\n",
    "    # Train and test patients\n",
    "    train_patients = unique_patients[train_idx]\n",
    "    test_patients = unique_patients[test_idx]\n",
    "\n",
    "    # Train and test data\n",
    "    train_data = data[data['PT_ID'].isin(train_patients)]\n",
    "    test_data = data[data['PT_ID'].isin(test_patients)]\n",
    "\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data['CRS_in_6_hours']\n",
    "    X_test = test_data[feature_cols]\n",
    "    y_test = test_data['CRS_in_6_hours']\n",
    "\n",
    "    # Fit CatBoost model\n",
    "    catboost_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_prob = catboost_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Determine best threshold\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    best_bal_acc = 0.0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred_th = (y_prob >= th).astype(int)\n",
    "        rec_class0 = recall_score(y_test, y_pred_th, pos_label=0)\n",
    "        rec_class1 = recall_score(y_test, y_pred_th, pos_label=1)\n",
    "        bal_acc = 0.5 * (rec_class0 + rec_class1)\n",
    "        if bal_acc > best_bal_acc:\n",
    "            best_bal_acc = bal_acc\n",
    "            best_threshold = th\n",
    "\n",
    "    # Use best threshold\n",
    "    y_pred = (y_prob >= best_threshold).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, digits=2, output_dict=True)\n",
    "\n",
    "    # Log metrics\n",
    "    print(f\"Best Threshold: {best_threshold:.3f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {best_bal_acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=2))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    cv_accuracies.append(acc)\n",
    "    cv_auc_scores.append(auc)\n",
    "    cv_classification_reports.append(class_report)\n",
    "    aggregate_conf_matrix += conf_matrix\n",
    "\n",
    "# Cross-validation results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(cv_accuracies)}\")\n",
    "print(f\"Average AUC-ROC: {np.mean(cv_auc_scores)}\")\n",
    "print(\"Aggregated Confusion Matrix:\\n\", aggregate_conf_matrix)\n",
    "\n",
    "# Class-specific accuracy\n",
    "tn, fp, fn, tp = aggregate_conf_matrix.ravel()\n",
    "class0_accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "class1_accuracy = tp / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for class 0: {class0_accuracy}\")\n",
    "print(f\"Accuracy for class 1: {class1_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpaVW6-DyB9l"
   },
   "source": [
    "**c. XGBoost Model Training**\n",
    "\n",
    "\n",
    "In this section, an XGBoost model is trained and evaluated using the same methodology. Random oversampling is applied and performance metrics are calculated to compare against other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAMLL-pGoAjf",
    "outputId": "40c7896f-994e-457a-e2b8-f64310d6f716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Accuracy: 0.5661353170386114\n",
      "AUC-ROC Score: 0.5724749162322825\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.60      0.71     24576\n",
      "           1       0.11      0.34      0.17      3654\n",
      "\n",
      "    accuracy                           0.57     28230\n",
      "   macro avg       0.48      0.47      0.44     28230\n",
      "weighted avg       0.76      0.57      0.64     28230\n",
      "\n",
      "\n",
      "Fold 2/5\n",
      "Accuracy: 0.802492764447764\n",
      "AUC-ROC Score: 0.8773465086867599\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87     15187\n",
      "           1       0.74      0.49      0.59      6235\n",
      "\n",
      "    accuracy                           0.80     21422\n",
      "   macro avg       0.78      0.71      0.73     21422\n",
      "weighted avg       0.80      0.80      0.79     21422\n",
      "\n",
      "\n",
      "Fold 3/5\n",
      "Accuracy: 0.6589673082798656\n",
      "AUC-ROC Score: 0.7157988739026837\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76     26456\n",
      "           1       0.30      0.60      0.40      6274\n",
      "\n",
      "    accuracy                           0.66     32730\n",
      "   macro avg       0.59      0.64      0.58     32730\n",
      "weighted avg       0.77      0.66      0.69     32730\n",
      "\n",
      "\n",
      "Fold 4/5\n",
      "Accuracy: 0.866988981335732\n",
      "AUC-ROC Score: 0.9259718176352766\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92     15756\n",
      "           1       0.46      0.88      0.60      2032\n",
      "\n",
      "    accuracy                           0.87     17788\n",
      "   macro avg       0.72      0.87      0.76     17788\n",
      "weighted avg       0.92      0.87      0.88     17788\n",
      "\n",
      "\n",
      "Fold 5/5\n",
      "Accuracy: 0.8373213692256564\n",
      "AUC-ROC Score: 0.9267768780926675\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91     11856\n",
      "           1       0.08      1.00      0.16       180\n",
      "\n",
      "    accuracy                           0.84     12036\n",
      "   macro avg       0.54      0.92      0.53     12036\n",
      "weighted avg       0.99      0.84      0.90     12036\n",
      "\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.7463811480655258\n",
      "Average AUC-ROC: 0.803673798909934\n",
      "Aggregated Confusion Matrix:\n",
      " [[70210 23621]\n",
      " [ 8344 10031]]\n",
      "Accuracy for class 0: 0.7482601698798904\n",
      "Accuracy for class 1: 0.5459047619047619\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import xgboost as xgb\n",
    "\n",
    "if 'cutoff_date' in data.columns:\n",
    "    data = data.drop(columns=['cutoff_date'])\n",
    "\n",
    "if 'datetime' in data.columns:\n",
    "    data = data.drop(columns=['datetime'])\n",
    "\n",
    "\n",
    "drop_cols = ['PT_ID', 'CRS on date (0 No, 1 Yes)', 'Agent (JNJ/BMS/Caribou)', 'CRS_in_6_hours']\n",
    "feature_cols = [col for col in data.columns if col not in drop_cols]\n",
    "\n",
    "unique_patients = data['PT_ID'].unique()\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "cv_accuracies = []\n",
    "cv_auc_scores = []\n",
    "cv_classification_reports = []\n",
    "aggregate_conf_matrix = np.array([[0, 0],\n",
    "                                  [0, 0]])\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(unique_patients)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "\n",
    "    train_patients = unique_patients[train_idx]\n",
    "    test_patients = unique_patients[test_idx]\n",
    "\n",
    "    train_data = data[data['PT_ID'].isin(train_patients)]\n",
    "    test_data = data[data['PT_ID'].isin(test_patients)]\n",
    "\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data['CRS_in_6_hours']\n",
    "\n",
    "    X_test = test_data[feature_cols]\n",
    "    y_test = test_data['CRS_in_6_hours']\n",
    "\n",
    "\n",
    "    # Random Oversampling\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_resampled, label=y_train_resampled)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1\n",
    "    }\n",
    "\n",
    "    model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "    y_prob = model.predict(dtest)\n",
    "    threshold = 0.01\n",
    "    y_pred = (y_prob > threshold).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"AUC-ROC Score:\", auc_score)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    cv_accuracies.append(accuracy)\n",
    "    cv_auc_scores.append(auc_score)\n",
    "    cv_classification_reports.append(class_report)\n",
    "    aggregate_conf_matrix += conf_matrix\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(cv_accuracies)}\")\n",
    "print(f\"Average AUC-ROC: {np.mean(cv_auc_scores)}\")\n",
    "print(\"Aggregated Confusion Matrix:\\n\", aggregate_conf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = aggregate_conf_matrix.ravel()\n",
    "class0_accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "class1_accuracy = tp / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for class 0: {class0_accuracy}\")\n",
    "print(f\"Accuracy for class 1: {class1_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVFdG2b2Z-RF"
   },
   "source": [
    "d. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BGqudt0YXnd",
    "outputId": "6463a851-177c-48ed-d5d2-92044d8ddb88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Best Threshold: 0.980\n",
      "Accuracy: 0.7873\n",
      "AUC-ROC: 0.7056\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88     24576\n",
      "           1       0.24      0.31      0.27      3654\n",
      "\n",
      "    accuracy                           0.79     28230\n",
      "   macro avg       0.57      0.58      0.57     28230\n",
      "weighted avg       0.81      0.79      0.80     28230\n",
      "\n",
      "\n",
      "Fold 2/5\n",
      "Best Threshold: 0.010\n",
      "Accuracy: 0.6967\n",
      "AUC-ROC: 0.8334\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.82     15187\n",
      "           1       0.36      0.05      0.09      6235\n",
      "\n",
      "    accuracy                           0.70     21422\n",
      "   macro avg       0.53      0.51      0.45     21422\n",
      "weighted avg       0.61      0.70      0.61     21422\n",
      "\n",
      "\n",
      "Fold 3/5\n",
      "Best Threshold: 1.000\n",
      "Accuracy: 0.4859\n",
      "AUC-ROC: 0.6160\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.45      0.59     26456\n",
      "           1       0.21      0.62      0.32      6274\n",
      "\n",
      "    accuracy                           0.49     32730\n",
      "   macro avg       0.52      0.54      0.45     32730\n",
      "weighted avg       0.72      0.49      0.54     32730\n",
      "\n",
      "\n",
      "Fold 4/5\n",
      "Best Threshold: 0.010\n",
      "Accuracy: 0.9278\n",
      "AUC-ROC: 0.9631\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     15756\n",
      "           1       0.87      0.43      0.58      2032\n",
      "\n",
      "    accuracy                           0.93     17788\n",
      "   macro avg       0.90      0.71      0.77     17788\n",
      "weighted avg       0.92      0.93      0.92     17788\n",
      "\n",
      "\n",
      "Fold 5/5\n",
      "Best Threshold: 0.990\n",
      "Accuracy: 0.0926\n",
      "AUC-ROC: 0.6756\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.15     11856\n",
      "           1       0.02      1.00      0.03       180\n",
      "\n",
      "    accuracy                           0.09     12036\n",
      "   macro avg       0.51      0.54      0.09     12036\n",
      "weighted avg       0.99      0.09      0.14     12036\n",
      "\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.5980352277133629\n",
      "Average AUC-ROC: 0.7587396273703753\n",
      "Aggregated Confusion Matrix:\n",
      " [[64238 29593]\n",
      " [11944  6431]]\n",
      "Accuracy for class 0: 0.6846138269868167\n",
      "Accuracy for class 1: 0.34998639455782315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, recall_score, confusion_matrix\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=42, class_weight='balanced', solver='liblinear')\n",
    "\n",
    "cv_accuracies = []\n",
    "cv_auc_scores = []\n",
    "cv_classification_reports = []\n",
    "aggregate_conf_matrix = np.array([[0, 0],\n",
    "                                  [0, 0]])\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(unique_patients)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "\n",
    "    train_patients = unique_patients[train_idx]\n",
    "    test_patients = unique_patients[test_idx]\n",
    "\n",
    "    train_data = data[data['PT_ID'].isin(train_patients)]\n",
    "    test_data = data[data['PT_ID'].isin(test_patients)]\n",
    "\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data['CRS_in_6_hours']\n",
    "    X_test = test_data[feature_cols]\n",
    "    y_test = test_data['CRS_in_6_hours']\n",
    "\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "    y_prob = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Determine best threshold\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    best_bal_acc = 0.0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred_th = (y_prob >= th).astype(int)\n",
    "        rec_class0 = recall_score(y_test, y_pred_th, pos_label=0)\n",
    "        rec_class1 = recall_score(y_test, y_pred_th, pos_label=1)\n",
    "        bal_acc = 0.5 * (rec_class0 + rec_class1)\n",
    "        if bal_acc > best_bal_acc:\n",
    "            best_bal_acc = bal_acc\n",
    "            best_threshold = th\n",
    "\n",
    "    y_pred = (y_prob >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, digits=2, output_dict=True)\n",
    "\n",
    "    print(f\"Best Threshold: {best_threshold:.3f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=2))\n",
    "\n",
    "    cv_accuracies.append(acc)\n",
    "    cv_auc_scores.append(auc)\n",
    "    cv_classification_reports.append(class_report)\n",
    "    aggregate_conf_matrix += conf_matrix\n",
    "\n",
    "# Cross-validation summary\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(cv_accuracies)}\")\n",
    "print(f\"Average AUC-ROC: {np.mean(cv_auc_scores)}\")\n",
    "print(\"Aggregated Confusion Matrix:\\n\", aggregate_conf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = aggregate_conf_matrix.ravel()\n",
    "class0_accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "class1_accuracy = tp / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for class 0: {class0_accuracy}\")\n",
    "print(f\"Accuracy for class 1: {class1_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVyETX81aHfW"
   },
   "source": [
    "e. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-40fpy0YdeG",
    "outputId": "d999e0eb-1e64-4f26-b556-9a0e576096ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Best Threshold: 0.180\n",
      "Accuracy: 0.5558\n",
      "AUC-ROC: 0.7300\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.49      0.66     24576\n",
      "           1       0.22      0.96      0.36      3654\n",
      "\n",
      "    accuracy                           0.56     28230\n",
      "   macro avg       0.61      0.73      0.51     28230\n",
      "weighted avg       0.89      0.56      0.62     28230\n",
      "\n",
      "\n",
      "Fold 2/5\n",
      "Best Threshold: 0.060\n",
      "Accuracy: 0.8255\n",
      "AUC-ROC: 0.7586\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87     15187\n",
      "           1       0.68      0.75      0.71      6235\n",
      "\n",
      "    accuracy                           0.83     21422\n",
      "   macro avg       0.79      0.80      0.79     21422\n",
      "weighted avg       0.83      0.83      0.83     21422\n",
      "\n",
      "\n",
      "Fold 3/5\n",
      "Best Threshold: 0.180\n",
      "Accuracy: 0.6115\n",
      "AUC-ROC: 0.7729\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.54      0.69     26456\n",
      "           1       0.32      0.90      0.47      6274\n",
      "\n",
      "    accuracy                           0.61     32730\n",
      "   macro avg       0.64      0.72      0.58     32730\n",
      "weighted avg       0.84      0.61      0.65     32730\n",
      "\n",
      "\n",
      "Fold 4/5\n",
      "Best Threshold: 0.280\n",
      "Accuracy: 0.7992\n",
      "AUC-ROC: 0.9019\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87     15756\n",
      "           1       0.36      0.97      0.52      2032\n",
      "\n",
      "    accuracy                           0.80     17788\n",
      "   macro avg       0.68      0.87      0.70     17788\n",
      "weighted avg       0.92      0.80      0.83     17788\n",
      "\n",
      "\n",
      "Fold 5/5\n",
      "Best Threshold: 0.430\n",
      "Accuracy: 0.9064\n",
      "AUC-ROC: 0.9137\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     11856\n",
      "           1       0.14      1.00      0.24       180\n",
      "\n",
      "    accuracy                           0.91     12036\n",
      "   macro avg       0.57      0.95      0.60     12036\n",
      "weighted avg       0.99      0.91      0.94     12036\n",
      "\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.7396733039935669\n",
      "Average AUC-ROC: 0.8154349192177044\n",
      "Aggregated Confusion Matrix:\n",
      " [[62514 31317]\n",
      " [ 2375 16000]]\n",
      "Accuracy for class 0: 0.66624036832177\n",
      "Accuracy for class 1: 0.8707482993197279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "cv_accuracies = []\n",
    "cv_auc_scores = []\n",
    "cv_classification_reports = []\n",
    "aggregate_conf_matrix = np.array([[0, 0],\n",
    "                                  [0, 0]])\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(unique_patients)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "\n",
    "    train_patients = unique_patients[train_idx]\n",
    "    test_patients = unique_patients[test_idx]\n",
    "\n",
    "    train_data = data[data['PT_ID'].isin(train_patients)]\n",
    "    test_data = data[data['PT_ID'].isin(test_patients)]\n",
    "\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data['CRS_in_6_hours']\n",
    "    X_test = test_data[feature_cols]\n",
    "    y_test = test_data['CRS_in_6_hours']\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    best_bal_acc = 0.0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred_th = (y_prob >= th).astype(int)\n",
    "        rec_class0 = recall_score(y_test, y_pred_th, pos_label=0)\n",
    "        rec_class1 = recall_score(y_test, y_pred_th, pos_label=1)\n",
    "        bal_acc = 0.5 * (rec_class0 + rec_class1)\n",
    "        if bal_acc > best_bal_acc:\n",
    "            best_bal_acc = bal_acc\n",
    "            best_threshold = th\n",
    "\n",
    "    y_pred = (y_prob >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, digits=2, output_dict=True)\n",
    "\n",
    "    print(f\"Best Threshold: {best_threshold:.3f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=2))\n",
    "\n",
    "    cv_accuracies.append(acc)\n",
    "    cv_auc_scores.append(auc)\n",
    "    cv_classification_reports.append(class_report)\n",
    "    aggregate_conf_matrix += conf_matrix\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(cv_accuracies)}\")\n",
    "print(f\"Average AUC-ROC: {np.mean(cv_auc_scores)}\")\n",
    "print(\"Aggregated Confusion Matrix:\\n\", aggregate_conf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = aggregate_conf_matrix.ravel()\n",
    "class0_accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "class1_accuracy = tp / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for class 0: {class0_accuracy}\")\n",
    "print(f\"Accuracy for class 1: {class1_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujVmXJX8aLSh"
   },
   "source": [
    "f. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQ0NcsECYmVq",
    "outputId": "14a5a065-3aa0-408a-f4f8-b8ee3cc736d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Best Threshold: 0.810\n",
      "Accuracy: 0.7460\n",
      "AUC-ROC: 0.4751\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85     24576\n",
      "           1       0.17      0.24      0.20      3654\n",
      "\n",
      "    accuracy                           0.75     28230\n",
      "   macro avg       0.52      0.53      0.52     28230\n",
      "weighted avg       0.79      0.75      0.76     28230\n",
      "\n",
      "\n",
      "Fold 2/5\n",
      "Best Threshold: 0.010\n",
      "Accuracy: 0.7519\n",
      "AUC-ROC: 0.6303\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84     15187\n",
      "           1       0.65      0.33      0.43      6235\n",
      "\n",
      "    accuracy                           0.75     21422\n",
      "   macro avg       0.71      0.63      0.64     21422\n",
      "weighted avg       0.73      0.75      0.72     21422\n",
      "\n",
      "\n",
      "Fold 3/5\n",
      "Best Threshold: 0.010\n",
      "Accuracy: 0.8245\n",
      "AUC-ROC: 0.6158\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     26456\n",
      "           1       0.59      0.28      0.38      6274\n",
      "\n",
      "    accuracy                           0.82     32730\n",
      "   macro avg       0.72      0.62      0.64     32730\n",
      "weighted avg       0.80      0.82      0.80     32730\n",
      "\n",
      "\n",
      "Fold 4/5\n",
      "Best Threshold: 0.010\n",
      "Accuracy: 0.8874\n",
      "AUC-ROC: 0.6159\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     15756\n",
      "           1       0.51      0.26      0.35      2032\n",
      "\n",
      "    accuracy                           0.89     17788\n",
      "   macro avg       0.71      0.62      0.64     17788\n",
      "weighted avg       0.87      0.89      0.87     17788\n",
      "\n",
      "\n",
      "Fold 5/5\n",
      "Best Threshold: 0.000\n",
      "Accuracy: 0.0150\n",
      "AUC-ROC: 0.4840\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     11856\n",
      "           1       0.01      1.00      0.03       180\n",
      "\n",
      "    accuracy                           0.01     12036\n",
      "   macro avg       0.01      0.50      0.01     12036\n",
      "weighted avg       0.00      0.01      0.00     12036\n",
      "\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.6449520206122473\n",
      "Average AUC-ROC: 0.5642107342543488\n",
      "Aggregated Confusion Matrix:\n",
      " [[74752 19079]\n",
      " [13009  5366]]\n",
      "Accuracy for class 0: 0.7966663469429079\n",
      "Accuracy for class 1: 0.29202721088435374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "cv_accuracies = []\n",
    "cv_auc_scores = []\n",
    "cv_classification_reports = []\n",
    "aggregate_conf_matrix = np.array([[0, 0],\n",
    "                                  [0, 0]])\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(unique_patients)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "\n",
    "    train_patients = unique_patients[train_idx]\n",
    "    test_patients = unique_patients[test_idx]\n",
    "\n",
    "    train_data = data[data['PT_ID'].isin(train_patients)]\n",
    "    test_data = data[data['PT_ID'].isin(test_patients)]\n",
    "\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data['CRS_in_6_hours']\n",
    "    X_test = test_data[feature_cols]\n",
    "    y_test = test_data['CRS_in_6_hours']\n",
    "\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_prob = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    best_bal_acc = 0.0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred_th = (y_prob >= th).astype(int)\n",
    "        rec_class0 = recall_score(y_test, y_pred_th, pos_label=0)\n",
    "        rec_class1 = recall_score(y_test, y_pred_th, pos_label=1)\n",
    "        bal_acc = 0.5 * (rec_class0 + rec_class1)\n",
    "        if bal_acc > best_bal_acc:\n",
    "            best_bal_acc = bal_acc\n",
    "            best_threshold = th\n",
    "\n",
    "    y_pred = (y_prob >= best_threshold).astype(int)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, digits=2, output_dict=True)\n",
    "\n",
    "    print(f\"Best Threshold: {best_threshold:.3f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=2))\n",
    "\n",
    "    cv_accuracies.append(acc)\n",
    "    cv_auc_scores.append(auc)\n",
    "    cv_classification_reports.append(class_report)\n",
    "    aggregate_conf_matrix += conf_matrix\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(cv_accuracies)}\")\n",
    "print(f\"Average AUC-ROC: {np.mean(cv_auc_scores)}\")\n",
    "print(\"Aggregated Confusion Matrix:\\n\", aggregate_conf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = aggregate_conf_matrix.ravel()\n",
    "class0_accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "class1_accuracy = tp / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for class 0: {class0_accuracy}\")\n",
    "print(f\"Accuracy for class 1: {class1_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSBD1kL9o_qP"
   },
   "source": [
    "Results Evaluation\n",
    "\n",
    "Random Forest was selected because it offered a substantially higher Class 1 accuracy (~0.8707) than any other model.\n",
    "\n",
    "Although CatBoost had a slightly better AUC-ROC (0.8215 vs. 0.8154), its Class 1 accuracy was only about 0.4728.\n",
    "\n",
    "Random Forest’s balance of overall predictive strength and reliable detection of CRS cases at the 6-hour mark makes it the preferred model for practical clinical application, reducing the risk of failing to identify patients who need urgent attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLyg2cA-ZuKa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
